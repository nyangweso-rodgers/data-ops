version: "3"
services:
  ############################################################################
  # mongodb-community-server
  #
  mongodb-community-server:
    #image: mongodb/mongodb-community-server:latest
    image: mongodb/mongodb-community-server:7.0.7-ubi8 #https://hub.docker.com/r/mongodb/mongodb-community-server
    container_name: mongodb-community-server
    ports:
      - "27017:27017"
    env_file:
      - .env
    environment:
      MONGODB_INITDB_ROOT_USERNAME: ${MONGODB_INITDB_ROOT_USERNAME}
      MONGODB_INITDB_ROOT_PASSWORD: ${MONGODB_INITDB_ROOT_PASSWORD}
    #entrypoint: ["mongod", "--auth", "--config", "/etc/mongod.conf"]
    #command: ["mongod","--replSet", "rs0", "--bind_ip_all"]
    volumes:
      - mongodb-community-server-volume:/data/db
    networks:
      - my-network
  ############################################################################
  # mongo
  #
  mongodb:
    #image: mongo:latest
    image: mongo:5.0.27 # https://hub.docker.com/_/mongo
    container_name: mongodb
    ports:
      - "27018:27018"
    env_file:
      - .env
    environment:
      MONGODB_INITDB_ROOT_USERNAME: ${MONGODB_INITDB_ROOT_USERNAME}
      MONGODB_INITDB_ROOT_PASSWORD: ${MONGODB_INITDB_ROOT_PASSWORD}
    #command: [--auth]
    #command: ["mongod", "--replSet", "rs0", "--bind_ip_all"]
    #command: ["--replSet", "my-replica-set", "--bind_ip_all", "--port", "27017"]
    volumes:
      - mongodb-volume:/data/db
    #- ./init-replica-set.js:/docker-entrypoint-initdb.d/init-replica-set.js
    #healthcheck:
    #test: echo 'db.runCommand("ping").ok' | mongo --username ${MONGO_INITDB_ROOT_USERNAME} --password ${MONGO_INITDB_ROOT_PASSWORD} --authenticationDatabase admin --quiet
    #test: test $$(echo "rs.initiate({_id:'my-replica-set',members:[{_id:0,host:\"mongo:27017\"},{_id:1,host:\"mongo-secondary1:27018\"},{_id:2,host:\"mongo-secondary2:27019\"}]}).ok || rs.status().ok" | mongo --port 27017 --quiet) -eq 1
    #test: test $$(echo "db.adminCommand('ping').ok" | mongo --username ${MONGO_INITDB_ROOT_USERNAME} --password ${MONGO_INITDB_ROOT_PASSWORD} --quiet) -eq 1
    #interval: 10s
    #timeout: 5s
    #retries: 5
    #start_period: 30s
    #entrypoint: ["/usr/bin/mongod", "--replSet", "rsmongo", "--bind_ip_all"]
    #entrypoint: ["mongod", "--replSet", "rsmongo", "--bind_ip_all"]
    networks:
      - my-network
  ############################################################################
  # postgres DB
  #
  postgres:
    #image: postgres:latest
    #image: postgres:16.3
    image: postgres:16.3-alpine3.20 #https://hub.docker.com/layers/library/postgres/16.3-alpine3.20/images/sha256-5eb2698ee6a3331df0788e1786145dc248e9a33e98dd161c4d1168a9fdf12a01?context=explore
    container_name: postgres
    hostname: postgres
    restart: always
    ports:
      - "5432:5432"
    env_file:
      - .env
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_TEST_DB: ${POSTGRES_TEST_DB} # The PostgreSQL default database (automatically created at first launch)
    #command:["postgres","-c","wal_level=logical","-c","max_replication_slots=10","-c","max_wal_senders=10",]
    command: ["postgres", "-c", "wal_level=logical"]
    volumes:
      - postgres-volume:/var/lib/postgresql/data
    healthcheck:
      #test: ["CMD", "psql", "-U", "postgres", "-c", "SELECT 1"]
      #test: ["CMD", "psql", "-U", "admin", "-c", "SELECT 1"]
      test:
        [
          "CMD-SHELL",
          "PGPASSWORD=${POSTGRES_PASSWORD} psql -U ${POSTGRES_USER} -d ${POSTGRES_TEST_DB} -c 'SELECT 1'",
        ]
      interval: 10s
      timeout: 5s
      retries: 3
    #logging:
    #driver: "json-file"
    #options:
    #max-size: "2048m"
    networks:
      - my-network
  ############################################################################
  # pgadmin
  #
  pgadmin:
    #image: dpage/pgadmin4:latest
    image: dpage/pgadmin4:8.7 #https://hub.docker.com/layers/dpage/pgadmin4/8.7/images/sha256-198236db5d90e491354c351ccd02a21ce736030b72cd0f8b05430bc48a59d86b?context=explore
    container_name: postgres-pgadmin
    ports:
      - "5050:80"
    env_file:
      - .env
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_DEFAULT_EMAIL}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_DEFAULT_PASSWORD}
    volumes:
      - pgadmin-volume:/var/lib/pgadmin
    depends_on:
      - postgres
    networks:
      - my-network
  ############################################################################
  # zookeeper
  #
  zookeeper:
    #image: confluentinc/cp-zookeeper:latest
    image: confluentinc/cp-zookeeper:7.6.1
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_SERVER_ID: 1
      #ZOOKEEPER_SERVER_ID: 2
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper-volume:/var/lib/zookeeper/data
    #restart: on-failure
    healthcheck:
      test: echo srvr | nc zookeeper 2181 || exit 1
      #test: curl -s localhost:2181 || exit 1 # using curl to query the Zookeeper server status:
      start_period: 10s
      retries: 20
      interval: 10s
    networks:
      - my-network
  ############################################################################
  # kafka
  #
  kafka:
    # An important note about accessing Kafka from clients on other machines:
    # -----------------------------------------------------------------------
    #
    # The config used here exposes port 9092 for _external_ connections to the broker
    #i.e. those from _outside_ the docker network. This could be from the host machine
    # running docker, or maybe further afield if you've got a more complicated setup.
    # If the latter is true, you will need to change the value 'localhost' in
    # KAFKA_ADVERTISED_LISTENERS to one that is resolvable to the docker host from those
    # remote clients
    #
    # For connections _internal_ to the docker network, such as from other services and components, use kafka:29092.
    #
    # See https://rmoff.net/2018/08/02/kafka-listeners-explained/ for details
    #
    #image: confluentinc/cp-kafka:latest
    image: confluentinc/cp-kafka:7.6.1
    hostname: kafka
    container_name: kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "29092:29092"
      #- "9101:9101"
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_DEFAULT_REPLICATION_FACTOR: "2"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"

      #KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9101,PLAINTEXT_INTERNAL://0.0.0.0:29091
      #KAFKA_LISTENERS: PLAINTEXT://kafka:29092, PLAINTEXT_HOST://localhost:9101
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092

      #KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9101
      #KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9101,PLAINTEXT_INTERNAL://kafka:29091
      #KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:8098
      #KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092
      #KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092

      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT, PLAINTEXT_HOST:PLAINTEXT
      #KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT

      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      #KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL

      #KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100

      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      #KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2

      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      #KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 2

      KAFKA_JMX_PORT: 9092
      KAFKA_JMX_HOSTNAME: localhost

      #KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      #KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1

      #KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      #KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka:29092
      CONFLUENT_METRICS_REPORTER_ZOOKEEPER_CONNECT: zookeeper:2181
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      CONFLUENT_METRICS_ENABLE: "true"
      CONFLUENT_SUPPORT_CUSTOMER_ID: "anonymous"
    #restart: on-failure
    volumes:
      - kafka-volume:/var/lib/kafka/data
    healthcheck:
      test: nc -z localhost 9092 || exit -1
      start_period: 15s
      interval: 5s
      timeout: 10s
      retries: 10
    networks:
      - my-network
  ############################################################################
  # schema-registry
  #
  schema-registry:
    image: confluentinc/cp-schema-registry:7.6.1
    #image: confluentinc/cp-schema-registry:latest
    container_name: schema-registry
    hostname: schema-registry
    restart: unless-stopped
    depends_on:
      kafka:
        condition: service_healthy
      zookeeper:
        condition: service_started
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: zookeeper:2181

      #SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9101
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka:29092

      #SCHEMA_REGISTRY_BOOTSTRAP_SERVERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9101

      #SCHEMA_REGISTRY_LISTENERS: http://schema-registry:8081
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081

      #SCHEMA_REGISTRY_KAFKASTORE_TOPIC_REPLICATION_FACTOR: 1
      SCHEMA_REGISTRY_DEBUG: "true"
    healthcheck:
      start_period: 10s
      interval: 10s
      retries: 20
      test: curl --user superUser:superUser --fail --silent --insecure http://localhost:8081/subjects --output /dev/null || exit 1
    networks:
      - my-network
  ############################################################################
  # ksqldb-server
  #
  ksqldb-server:
    image: confluentinc/cp-ksqldb-server:latest
    #image: confluentinc/cp-ksqldb-server:7.5.3
    hostname: ksqldb-server
    container_name: ksqldb-server
    depends_on:
      - kafka
      - schema-registry
    ports:
      - "8088:8088"
    environment:
      KSQL_CONFIG_DIR: "/etc/ksqldb"
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_BOOTSTRAP_SERVERS: kafka:29092
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: "true"
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: "true"
      KSQL_KSQL_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      KSQL_HOST_NAME: ksqldb-server
      KSQL_CONNECT_URL: "http://connect:8083"
    networks:
      - my-network
  ############################################################################
  # debezium
  #
  debezium:
    image: debezium/connect:latest #https://hub.docker.com/r/debezium/connect
    restart: always
    container_name: debezium
    hostname: debezium
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_healthy
    ports:
      - "8083:8083"
    environment:
      BOOTSTRAP_SERVERS: kafka:29092
      GROUP_ID: 1
      #CONFIG_STORAGE_TOPIC: connect_configs
      CONFIG_STORAGE_TOPIC: debezium_connect_configs
      #STATUS_STORAGE_TOPIC: connect_statuses
      STATUS_STORAGE_TOPIC: debezium_connect_statuses
      #OFFSET_STORAGE_TOPIC: connect_offsets
      OFFSET_STORAGE_TOPIC: debezium_connect_offsets
      CONFIG_STORAGE_REPLICATION_FACTOR: 2
      OFFSET_STORAGE_REPLICATION_FACTOR: 2
      STATUS_STORAGE_REPLICATION_FACTOR: 2
      #CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      #CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      ENABLE_DEBEZIUM_SCRIPTING: "true"
      #CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "false"
      #CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      PLUGIN_PATH: /kafka/connect/plugins #added as part of the sink connector configuration
      GOOGLE_APPLICATION_CREDENTIALS: /etc/debezium/bigquery-keyfile.json # Specify the path inside the container
    healthcheck:
      test:
        [
          "CMD",
          "curl",
          "--silent",
          "--fail",
          "-X",
          "GET",
          "http://localhost:8083/connectors",
        ]
      start_period: 10s
      interval: 10s
      timeout: 5s
      retries: 5
    volumes:
      - ./bigquery-keyfile.json:/etc/debezium/bigquery-keyfile.json # Mount the service account key
      - ./plugins:/kafka/connect/plugins # Mount the plugins directory
    networks:
      - my-network
  ############################################################################
  cp-kafka-connect: #https://hub.docker.com/r/confluentinc/cp-kafka-connect/tags
    #image: confluentinc/cp-kafka-connect:latest
    image: confluentinc/cp-kafka-connect:7.7.0
    container_name: cp-kafka-connect
    hostname: cp-kafka-connect
    depends_on:
      - kafka
      - postgres
    ports:
      - "8084:8084"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "kafka:29092"
      CONNECT_REST_ADVERTISED_HOST_NAME: cp-kafka-connect
      CONNECT_GROUP_ID: "kafka-connect"
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000

      #CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      #CONNECT_CONFIG_STORAGE_TOPIC: _kafka-connect-group-01-configs
      #CONNECT_CONFIG_STORAGE_TOPIC: "__connect-config"
      CONNECT_CONFIG_STORAGE_TOPIC: cp_connect_configs

      #CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      #CONNECT_OFFSET_STORAGE_TOPIC: _kafka-connect-group-01-offsets
      #CONNECT_OFFSET_STORAGE_TOPIC: "__connect-offsets"
      CONNECT_OFFSET_STORAGE_TOPIC: cp_connect_offsets

      #CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      #CONNECT_STATUS_STORAGE_TOPIC: _kafka-connect-group-01-status
      #CONNECT_STATUS_STORAGE_TOPIC: "__connect-status"
      CONNECT_STATUS_STORAGE_TOPIC: cp_connect_statuses

      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1

      #CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8085"
      #CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "true"

      #CONNECT_VALUE_CONVERTER: "io.confluent.connect.avro.AvroConverter"
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      #CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "true"

      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"

      CONNECT_ZOOKEEPER_CONNECT: "zookeeper1:2181"
    networks:
      - my-network
  ############################################################################
  # kafka-ui
  #
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - 8080:8080
    depends_on:
      - kafka
    environment:
      DYNAMIC_CONFIG_ENABLED: "true"
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_SCHEMA_REGISTRY: http://schema-registry:8081
      KAFKA_CLUSTERS_0_ZOOKEEPER=zookeeper: 2181
    #volumes:
    #- ~/kui/config.yml:/etc/kafkaui/dynamic_config.yaml
    networks:
      - my-network
  ############################################################################
  # ksqldb-cli
  #
  ksqldb-cli:
    #image: confluentinc/cp-ksqldb-cli:6.1.0
    image: confluentinc/cp-ksqldb-cli:latest # usage -> docker-compose exec ksqldb-cli ksql http://ksqldb-server:8088
    container_name: ksqldb-cli
    depends_on:
      - kafka
      - debezium
      - ksqldb-server
    entrypoint: /bin/sh
    tty: true
    networks:
      - my-network
  ############################################################################
  # debezium-ui
  #
  debezium-ui:
    image: debezium/debezium-ui:latest
    restart: always
    container_name: debezium-ui
    hostname: debezium-ui
    depends_on:
      debezium:
        condition: service_healthy
    ports:
      - "8082:8080"
      #- "8082:8082"
    environment:
      KAFKA_CONNECT_URIS: http://debezium:8083
    networks:
      - my-network
  ############################################################################
  # spring-boot-data-pipeline
  #
  spring-boot-data-pipeline:
    build:
      context: ./spring-boot-data-pipeline
      dockerfile: Dockerfile
    image: spring-boot-data-pipeline
    container_name: spring-boot-data-pipeline
    ports:
      - "9093:9093"
    depends_on:
      - kafka
    environment:
      SPRING_PROFILES_ACTIVE: dev
    networks:
      - my-network
  ############################################################################
  # Node.js Kafka Producer
  #
  node.js-kafka-client:
    build:
      context: ./kafka-clients/node.js-kafka-client
      dockerfile: Dockerfile
    image: node.js-kafka-client
    container_name: node.js-kafka-client
    ports:
      - "3004:3004"
    depends_on:
      - kafka
    networks:
      - my-network
  ############################################################################
  # metabase
  #
  #metabase:
  #image: metabase/metabase:latest
  #container_name: metabase
  #depends_on:
  #- postgres
  #ports:
  #- 3000:3000
  #environment:
  #MB_DB_TYPE: ${MB_DB_TYPE}
  #MB_DB_DBNAME: metabaseappdb
  #MB_DB_PORT: 5432
  #MB_DB_USER: metabase
  #MB_DB_PASS: mysecretpassword
  #MB_DB_HOST: postgres
  #healthcheck:
  #test: curl --fail -I http://localhost:3000/api/health || exit 1
  #interval: 15s
  #timeout: 5s
  #retries: 5
  ############################################################################
  # grafana
  #
  #grafana:
  #image: grafana/grafana:latest
  #ports:
  #- "3000:3000"
  #environment:
  #- GF_SECURITY_ADMIN_PASSWORD=123456
  ############################################################################
  # next.js app
  #
  next.js-web-portal:
    build:
      context: ./next.js-web-portal
      dockerfile: Dockerfile
    image: next.js-web-portal
    container_name: next.js-web-portal
    ports:
      - "3003:3003"
    depends_on:
      #- mongodb-community-server
      - postgres
    restart: always
    environment:
      #- MONGODB_URI_FOR_SURVEY_SERVICE=mongodb://${MONGO_INITDB_ROOT_USERNAME}:${MONGO_INITDB_ROOT_PASSWORD}@mongo:27017/survey-service?authSource=admin
      #MONGO_URI: ${MONGODB_COMMUNITY_SERVER_URI_FOR_SURVEY_SERVICE}
      MONGODB_ATLAS_URI_FOR_SURVEY_SERVICE: ${MONGODB_ATLAS_URI_FOR_SURVEY_SERVICE}
      PGHOST: ${PGHOST}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_TEST_DB: ${POSTGRES_TEST_DB}
      #POSTGRES_TEST_DATABASE_URL: ${POSTGRES_TEST_DATABASE_URL}
    env_file:
      - ./next.js-web-portal/.env
    #volumes:
    #- /next.js-web-portal/src/app/prisma
    #command: sh -c "npx prisma migrate deploy && npm run dev"
    #entrypoint: ["sh", "/migrate.sh"]  # Execute migrate.sh script first
    networks:
      - my-network
  ############################################################################
  # api - with Express.js and postgresql
  #
  express.js-and-postgres-api:
    build:
      context: ./apis/express.js-and-postgres-api
      dockerfile: Dockerfile
    image: express.js-and-postgres-api
    container_name: express.js-and-postgres-api
    ports:
      - "3005:3005"
    depends_on:
      - postgres
      - pgadmin
    #command: sh -c "npx prisma migrate dev --name init && npm start" #remove this line after the first deployment
    #command: ["sh", "-c", "npx prisma migrate dev --name init && npm start"] #This ensures that the migrations are applied in a non-interactive manner.
    # Add this line
    #tty: true # Enables interactive mode
    environment:
      PGHOST: ${PGHOST}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_USERS_DB: ${POSTGRES_USERS_DB}
    env_file:
      - ./apis/express.js-and-postgres-api/.env
    networks:
      - my-network
  ############################################################################
  #Superset
  #
  #superset:
  #image: alexmerced/dremio-superset
  #container_name: superset
  #ports:
  #- "8088:8088"
  #environment:
  #- ADMIN_USERNAME=admin
  #- ADMIN_EMAIL=admin@superset.com
  #- ADMIN_PASSWORD=admin
  ############################################################################
  # mongodb-change-stream-app
  #
  #mongodb-change-stream-app:
  #build:
  #context: ./mongodb-change-stream-app
  #dockerfile: Dockerfile
  #image: mongodb-change-stream-app
  #container_name: mongodb-change-stream-app
  #depends_on:
  #- mongodb-community-server
  #environment:
  #MONGO_URI: ${MONGODB_COMMUNITY_SERVER_URI_FOR_SURVEY_SERVICE}
  #ports:
  #- "4001:4001"

  ############################################################################
  # api-with-express-and-mongo
  #
  #api-with-mongo:
  #build:
  #context: ./api-with-mongo
  #dockerfile: Dockerfile
  #image: api-with-mongo
  #container_name: api-with-mongo
  #ports:
  #- "3200:3200"
  #depends_on:
  #- mongo
############################################################################
# networks
#
networks:
  my-network:
  #kafka-network:
  #driver: bridge
  #name: kafka-network
############################################################################
# volumes
#
volumes:
  mongodb-community-server-volume:
    name: mongodb-community-server-volume
    driver: local
  mongodb-volume:
    name: mongodb-volume
    driver: local
  postgres-volume:
    name: postgres-volume
    driver: local
    #driver_opts:
    #type: none
    #o: bind
    #device: ./data
  pgadmin-volume:
    name: pgadmin-volume
    driver: local
  zookeeper-volume:
    name: zookeeper-volume
    driver: local
  kafka-volume:
    name: kafka-volume
    driver: local
